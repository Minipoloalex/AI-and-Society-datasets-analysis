{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU fairlearn pandas scikit-learn scipy matplotlib seaborn ucimlrepo ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from scipy import stats\n",
    "\n",
    "from typing import Optional, Callable, List, Tuple, Mapping\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_uci_dataset(\n",
    "    id: int,\n",
    "    get_column_names: Optional[Callable[[np.ndarray], List[str]]] = None,\n",
    ") -> DataFrame:\n",
    "    dataset = fetch_ucirepo(id=id)\n",
    "    df = dataset.data.original\n",
    "\n",
    "    # Display metadata and variable information\n",
    "    print(\"Dataset Metadata:\")\n",
    "    print(dataset.metadata)\n",
    "    print(\"\\nVariable Information:\")\n",
    "    print(dataset.variables)\n",
    "\n",
    "    if get_column_names is not None:\n",
    "        column_names = get_column_names(dataset.variables)\n",
    "        print(df.columns)\n",
    "        df.columns = column_names\n",
    "\n",
    "    # Rename the last column to \"target\"\n",
    "    df = df.rename(columns={df.columns[-1]: \"target\"})\n",
    "\n",
    "    print(df.columns.values)\n",
    "\n",
    "    # Return the complete DataFrame with all features and target column labeled \"target\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"Adult\", \"Credit\", \"Bank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Metadata:\n",
      "{'uci_id': 2, 'name': 'Adult', 'repository_url': 'https://archive.ics.uci.edu/dataset/2/adult', 'data_url': 'https://archive.ics.uci.edu/static/public/2/data.csv', 'abstract': 'Predict whether annual income of an individual exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset. ', 'area': 'Social Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 48842, 'num_features': 14, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Age', 'Income', 'Education Level', 'Other', 'Race', 'Sex'], 'target_col': ['income'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1996, 'last_updated': 'Tue Sep 24 2024', 'dataset_doi': '10.24432/C5XW20', 'creators': ['Barry Becker', 'Ronny Kohavi'], 'intro_paper': None, 'additional_info': {'summary': \"Extraction was done by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\\n\\nPrediction task is to determine whether a person's income is over $50,000 a year.\\n\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Listing of attributes:\\r\\n\\r\\n>50K, <=50K.\\r\\n\\r\\nage: continuous.\\r\\nworkclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\\r\\nfnlwgt: continuous.\\r\\neducation: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\\r\\neducation-num: continuous.\\r\\nmarital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\\r\\noccupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\\r\\nrelationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\\r\\nrace: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\\r\\nsex: Female, Male.\\r\\ncapital-gain: continuous.\\r\\ncapital-loss: continuous.\\r\\nhours-per-week: continuous.\\r\\nnative-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.', 'citation': None}}\n",
      "\n",
      "Variable Information:\n",
      "              name     role  ... units missing_values\n",
      "0              age  Feature  ...  None             no\n",
      "1        workclass  Feature  ...  None            yes\n",
      "2           fnlwgt  Feature  ...  None             no\n",
      "3        education  Feature  ...  None             no\n",
      "4    education-num  Feature  ...  None             no\n",
      "5   marital-status  Feature  ...  None             no\n",
      "6       occupation  Feature  ...  None            yes\n",
      "7     relationship  Feature  ...  None             no\n",
      "8             race  Feature  ...  None             no\n",
      "9              sex  Feature  ...  None             no\n",
      "10    capital-gain  Feature  ...  None             no\n",
      "11    capital-loss  Feature  ...  None             no\n",
      "12  hours-per-week  Feature  ...  None             no\n",
      "13  native-country  Feature  ...  None            yes\n",
      "14          income   Target  ...  None             no\n",
      "\n",
      "[15 rows x 7 columns]\n",
      "['age' 'workclass' 'fnlwgt' 'education' 'education-num' 'marital-status'\n",
      " 'occupation' 'relationship' 'race' 'sex' 'capital-gain' 'capital-loss'\n",
      " 'hours-per-week' 'native-country' 'target']\n",
      "Dataset Metadata:\n",
      "{'uci_id': 350, 'name': 'Default of Credit Card Clients', 'repository_url': 'https://archive.ics.uci.edu/dataset/350/default+of+credit+card+clients', 'data_url': 'https://archive.ics.uci.edu/static/public/350/data.csv', 'abstract': \"This research aimed at the case of customers' default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods.\", 'area': 'Business', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 30000, 'num_features': 23, 'feature_types': ['Integer', 'Real'], 'demographics': ['Sex', 'Education Level', 'Marital Status', 'Age'], 'target_col': ['Y'], 'index_col': ['ID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2009, 'last_updated': 'Fri Mar 29 2024', 'dataset_doi': '10.24432/C55S3H', 'creators': ['I-Cheng Yeh'], 'intro_paper': {'ID': 365, 'type': 'NATIVE', 'title': 'The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients', 'authors': 'I. Yeh, Che-hui Lien', 'venue': 'Expert systems with applications', 'year': 2009, 'journal': None, 'DOI': '10.1016/j.eswa.2007.12.020', 'URL': 'https://www.semanticscholar.org/paper/1cacac4f0ea9fdff3cd88c151c94115a9fddcf33', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': \"This research aimed at the case of customers' default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. Because the real probability of default is unknown, this study presented the novel Sorting Smoothing Method to estimate the real probability of default. With the real probability of default as the response variable (Y), and the predictive probability of default as the independent variable (X), the simple linear regression result (Y = A + BX) shows that the forecasting model produced by artificial neural network has the highest coefficient of determination; its regression intercept (A) is close to zero, and regression coefficient (B) to one. Therefore, among the six data mining techniques, artificial neural network is the only one that can accurately estimate the real probability of default.\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables:\\r\\nX1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\\r\\nX2: Gender (1 = male; 2 = female).\\r\\nX3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\\r\\nX4: Marital status (1 = married; 2 = single; 3 = others).\\r\\nX5: Age (year).\\r\\nX6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\\r\\nX12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005. \\r\\nX18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.\\r\\n', 'citation': None}}\n",
      "\n",
      "Variable Information:\n",
      "   name     role     type  ...                 description units missing_values\n",
      "0    ID       ID  Integer  ...                        None  None             no\n",
      "1    X1  Feature  Integer  ...                   LIMIT_BAL  None             no\n",
      "2    X2  Feature  Integer  ...                         SEX  None             no\n",
      "3    X3  Feature  Integer  ...                   EDUCATION  None             no\n",
      "4    X4  Feature  Integer  ...                    MARRIAGE  None             no\n",
      "5    X5  Feature  Integer  ...                         AGE  None             no\n",
      "6    X6  Feature  Integer  ...                       PAY_0  None             no\n",
      "7    X7  Feature  Integer  ...                       PAY_2  None             no\n",
      "8    X8  Feature  Integer  ...                       PAY_3  None             no\n",
      "9    X9  Feature  Integer  ...                       PAY_4  None             no\n",
      "10  X10  Feature  Integer  ...                       PAY_5  None             no\n",
      "11  X11  Feature  Integer  ...                       PAY_6  None             no\n",
      "12  X12  Feature  Integer  ...                   BILL_AMT1  None             no\n",
      "13  X13  Feature  Integer  ...                   BILL_AMT2  None             no\n",
      "14  X14  Feature  Integer  ...                   BILL_AMT3  None             no\n",
      "15  X15  Feature  Integer  ...                   BILL_AMT4  None             no\n",
      "16  X16  Feature  Integer  ...                   BILL_AMT5  None             no\n",
      "17  X17  Feature  Integer  ...                   BILL_AMT6  None             no\n",
      "18  X18  Feature  Integer  ...                    PAY_AMT1  None             no\n",
      "19  X19  Feature  Integer  ...                    PAY_AMT2  None             no\n",
      "20  X20  Feature  Integer  ...                    PAY_AMT3  None             no\n",
      "21  X21  Feature  Integer  ...                    PAY_AMT4  None             no\n",
      "22  X22  Feature  Integer  ...                    PAY_AMT5  None             no\n",
      "23  X23  Feature  Integer  ...                    PAY_AMT6  None             no\n",
      "24    Y   Target   Binary  ...  default payment next month  None             no\n",
      "\n",
      "[25 rows x 7 columns]\n",
      "Index(['ID', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10',\n",
      "       'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20',\n",
      "       'X21', 'X22', 'X23', 'Y'],\n",
      "      dtype='object')\n",
      "[None 'limit_bal' 'sex' 'education' 'marriage' 'age' 'pay_0' 'pay_2'\n",
      " 'pay_3' 'pay_4' 'pay_5' 'pay_6' 'bill_amt1' 'bill_amt2' 'bill_amt3'\n",
      " 'bill_amt4' 'bill_amt5' 'bill_amt6' 'pay_amt1' 'pay_amt2' 'pay_amt3'\n",
      " 'pay_amt4' 'pay_amt5' 'pay_amt6' 'target']\n",
      "Dataset Metadata:\n",
      "{'uci_id': 222, 'name': 'Bank Marketing', 'repository_url': 'https://archive.ics.uci.edu/dataset/222/bank+marketing', 'data_url': 'https://archive.ics.uci.edu/static/public/222/data.csv', 'abstract': 'The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y).', 'area': 'Business', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 45211, 'num_features': 16, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Age', 'Occupation', 'Marital Status', 'Education Level'], 'target_col': ['y'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 2014, 'last_updated': 'Fri Aug 18 2023', 'dataset_doi': '10.24432/C5K306', 'creators': ['S. Moro', 'P. Rita', 'P. Cortez'], 'intro_paper': {'ID': 277, 'type': 'NATIVE', 'title': 'A data-driven approach to predict the success of bank telemarketing', 'authors': 'SÃ©rgio Moro, P. Cortez, P. Rita', 'venue': 'Decision Support Systems', 'year': 2014, 'journal': None, 'DOI': '10.1016/j.dss.2014.03.001', 'URL': 'https://www.semanticscholar.org/paper/cab86052882d126d43f72108c6cb41b295cc8a9e', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': \"The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. \\n\\nThere are four datasets: \\n1) bank-additional-full.csv with all examples (41188) and 20 inputs, ordered by date (from May 2008 to November 2010), very close to the data analyzed in [Moro et al., 2014]\\n2) bank-additional.csv with 10% of the examples (4119), randomly selected from 1), and 20 inputs.\\n3) bank-full.csv with all examples and 17 inputs, ordered by date (older version of this dataset with less inputs). \\n4) bank.csv with 10% of the examples and 17 inputs, randomly selected from 3 (older version of this dataset with less inputs). \\nThe smallest datasets are provided to test more computationally demanding machine learning algorithms (e.g., SVM). \\n\\nThe classification goal is to predict if the client will subscribe (yes/no) a term deposit (variable y).\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Input variables:\\n   # bank client data:\\n   1 - age (numeric)\\n   2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\\n                                       \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") \\n   3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\\n   4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\\n   5 - default: has credit in default? (binary: \"yes\",\"no\")\\n   6 - balance: average yearly balance, in euros (numeric) \\n   7 - housing: has housing loan? (binary: \"yes\",\"no\")\\n   8 - loan: has personal loan? (binary: \"yes\",\"no\")\\n   # related with the last contact of the current campaign:\\n   9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \\n  10 - day: last contact day of the month (numeric)\\n  11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\\n  12 - duration: last contact duration, in seconds (numeric)\\n   # other attributes:\\n  13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\\n  14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\\n  15 - previous: number of contacts performed before this campaign and for this client (numeric)\\n  16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\\n\\n  Output variable (desired target):\\n  17 - y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")\\n', 'citation': None}}\n",
      "\n",
      "Variable Information:\n",
      "           name     role  ...  units missing_values\n",
      "0           age  Feature  ...   None             no\n",
      "1           job  Feature  ...   None             no\n",
      "2       marital  Feature  ...   None             no\n",
      "3     education  Feature  ...   None             no\n",
      "4       default  Feature  ...   None             no\n",
      "5       balance  Feature  ...  euros             no\n",
      "6       housing  Feature  ...   None             no\n",
      "7          loan  Feature  ...   None             no\n",
      "8       contact  Feature  ...   None            yes\n",
      "9   day_of_week  Feature  ...   None             no\n",
      "10        month  Feature  ...   None             no\n",
      "11     duration  Feature  ...   None             no\n",
      "12     campaign  Feature  ...   None             no\n",
      "13        pdays  Feature  ...   None            yes\n",
      "14     previous  Feature  ...   None             no\n",
      "15     poutcome  Feature  ...   None            yes\n",
      "16            y   Target  ...   None             no\n",
      "\n",
      "[17 rows x 7 columns]\n",
      "['age' 'job' 'marital' 'education' 'default' 'balance' 'housing' 'loan'\n",
      " 'contact' 'day_of_week' 'month' 'duration' 'campaign' 'pdays' 'previous'\n",
      " 'poutcome' 'target']\n"
     ]
    }
   ],
   "source": [
    "adult = load_uci_dataset(2)\n",
    "credit_card = load_uci_dataset(\n",
    "    350, lambda dataset_variables: dataset_variables[\"description\"].str.lower()  # Ignore ID column\n",
    ")\n",
    "bank_marketing = load_uci_dataset(222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Adult\n",
      "   age         workclass  fnlwgt  ... hours-per-week  native-country target\n",
      "0   39         State-gov   77516  ...             40   United-States  <=50K\n",
      "1   50  Self-emp-not-inc   83311  ...             13   United-States  <=50K\n",
      "2   38           Private  215646  ...             40   United-States  <=50K\n",
      "3   53           Private  234721  ...             40   United-States  <=50K\n",
      "4   28           Private  338409  ...             40            Cuba  <=50K\n",
      "\n",
      "[5 rows x 15 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       47879 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      47876 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  48568 non-null  object\n",
      " 14  target          48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n",
      "None\n",
      "\n",
      "---\n",
      "\n",
      "Dataset: Credit\n",
      "description  None  limit_bal  sex  ...  pay_amt5  pay_amt6  target\n",
      "0               1      20000    2  ...         0         0       1\n",
      "1               2     120000    2  ...         0      2000       1\n",
      "2               3      90000    2  ...      1000      5000       0\n",
      "3               4      50000    2  ...      1069      1000       0\n",
      "4               5      50000    1  ...       689       679       0\n",
      "\n",
      "[5 rows x 25 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 25 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   None       30000 non-null  int64\n",
      " 1   limit_bal  30000 non-null  int64\n",
      " 2   sex        30000 non-null  int64\n",
      " 3   education  30000 non-null  int64\n",
      " 4   marriage   30000 non-null  int64\n",
      " 5   age        30000 non-null  int64\n",
      " 6   pay_0      30000 non-null  int64\n",
      " 7   pay_2      30000 non-null  int64\n",
      " 8   pay_3      30000 non-null  int64\n",
      " 9   pay_4      30000 non-null  int64\n",
      " 10  pay_5      30000 non-null  int64\n",
      " 11  pay_6      30000 non-null  int64\n",
      " 12  bill_amt1  30000 non-null  int64\n",
      " 13  bill_amt2  30000 non-null  int64\n",
      " 14  bill_amt3  30000 non-null  int64\n",
      " 15  bill_amt4  30000 non-null  int64\n",
      " 16  bill_amt5  30000 non-null  int64\n",
      " 17  bill_amt6  30000 non-null  int64\n",
      " 18  pay_amt1   30000 non-null  int64\n",
      " 19  pay_amt2   30000 non-null  int64\n",
      " 20  pay_amt3   30000 non-null  int64\n",
      " 21  pay_amt4   30000 non-null  int64\n",
      " 22  pay_amt5   30000 non-null  int64\n",
      " 23  pay_amt6   30000 non-null  int64\n",
      " 24  target     30000 non-null  int64\n",
      "dtypes: int64(25)\n",
      "memory usage: 5.7 MB\n",
      "None\n",
      "\n",
      "---\n",
      "\n",
      "Dataset: Bank\n",
      "   age           job  marital  education  ... pdays  previous poutcome target\n",
      "0   58    management  married   tertiary  ...    -1         0      NaN     no\n",
      "1   44    technician   single  secondary  ...    -1         0      NaN     no\n",
      "2   33  entrepreneur  married  secondary  ...    -1         0      NaN     no\n",
      "3   47   blue-collar  married        NaN  ...    -1         0      NaN     no\n",
      "4   33           NaN   single        NaN  ...    -1         0      NaN     no\n",
      "\n",
      "[5 rows x 17 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   age          45211 non-null  int64 \n",
      " 1   job          44923 non-null  object\n",
      " 2   marital      45211 non-null  object\n",
      " 3   education    43354 non-null  object\n",
      " 4   default      45211 non-null  object\n",
      " 5   balance      45211 non-null  int64 \n",
      " 6   housing      45211 non-null  object\n",
      " 7   loan         45211 non-null  object\n",
      " 8   contact      32191 non-null  object\n",
      " 9   day_of_week  45211 non-null  int64 \n",
      " 10  month        45211 non-null  object\n",
      " 11  duration     45211 non-null  int64 \n",
      " 12  campaign     45211 non-null  int64 \n",
      " 13  pdays        45211 non-null  int64 \n",
      " 14  previous     45211 non-null  int64 \n",
      " 15  poutcome     8252 non-null   object\n",
      " 16  target       45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n",
      "None\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, dataset in zip(dataset_names, [adult, credit_card, bank_marketing]):\n",
    "    print(f\"Dataset: {name}\")\n",
    "    print(dataset.head())\n",
    "    print(dataset.info())\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(\n",
    "    df: DataFrame,\n",
    "    features: List[str],\n",
    "    sensitive_attribute: str,\n",
    "    columns_names: Optional[List[str]] = None,\n",
    "    convert_target: Optional[Callable[[str], int]] = None,\n",
    ") -> Tuple[np.ndarray[np.ndarray], np.ndarray, np.ndarray]:\n",
    "    attributes = np.concatenate((np.array(features), np.array([sensitive_attribute, \"target\"])))\n",
    "    print(attributes)\n",
    "    df = df[attributes]\n",
    "    print(df)\n",
    "    df = df.dropna()\n",
    "\n",
    "    X = df[features]\n",
    "    y = df[\"target\"]\n",
    "\n",
    "    if convert_target is not None:\n",
    "        y = y.apply(convert_target).astype(int)\n",
    "\n",
    "    if columns_names is not None:\n",
    "        X.columns = columns_names\n",
    "\n",
    "    sensitive_series = df[sensitive_attribute]  # e.g. \"sex\" or \"race\"\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    return X, y.values, sensitive_series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age' 'education-num' 'capital-gain' 'capital-loss' 'hours-per-week'\n",
      " 'sex' 'target']\n",
      "       age  education-num  capital-gain  ...  hours-per-week     sex  target\n",
      "0       39             13          2174  ...              40    Male   <=50K\n",
      "1       50             13             0  ...              13    Male   <=50K\n",
      "2       38              9             0  ...              40    Male   <=50K\n",
      "3       53              7             0  ...              40    Male   <=50K\n",
      "4       28             13             0  ...              40  Female   <=50K\n",
      "...    ...            ...           ...  ...             ...     ...     ...\n",
      "48837   39             13             0  ...              36  Female  <=50K.\n",
      "48838   64              9             0  ...              40    Male  <=50K.\n",
      "48839   38             13             0  ...              50    Male  <=50K.\n",
      "48840   44             13          5455  ...              40    Male  <=50K.\n",
      "48841   35             13             0  ...              60    Male   >50K.\n",
      "\n",
      "[48842 rows x 7 columns]\n",
      "['limit_bal' 'education' 'age' 'pay_0' 'pay_2' 'pay_3' 'pay_4' 'pay_5'\n",
      " 'pay_6' 'bill_amt1' 'bill_amt2' 'bill_amt3' 'bill_amt4' 'bill_amt5'\n",
      " 'bill_amt6' 'pay_amt1' 'pay_amt2' 'pay_amt3' 'pay_amt4' 'pay_amt5'\n",
      " 'pay_amt6' 'sex' 'target']\n",
      "description  limit_bal  education  age  pay_0  ...  pay_amt5  pay_amt6  sex  target\n",
      "0                20000          2   24      2  ...         0         0    2       1\n",
      "1               120000          2   26     -1  ...         0      2000    2       1\n",
      "2                90000          2   34      0  ...      1000      5000    2       0\n",
      "3                50000          2   37      0  ...      1069      1000    2       0\n",
      "4                50000          2   57     -1  ...       689       679    1       0\n",
      "...                ...        ...  ...    ...  ...       ...       ...  ...     ...\n",
      "29995           220000          3   39      0  ...      5000      1000    1       0\n",
      "29996           150000          3   43     -1  ...         0         0    1       0\n",
      "29997            30000          2   37      4  ...      2000      3100    1       1\n",
      "29998            80000          3   41      1  ...     52964      1804    1       1\n",
      "29999            50000          2   46      0  ...      1000      1000    1       1\n",
      "\n",
      "[30000 rows x 23 columns]\n",
      "['age' 'balance' 'campaign' 'pdays' 'previous' 'marital' 'target']\n",
      "       age  balance  campaign  pdays  previous   marital target\n",
      "0       58     2143         1     -1         0   married     no\n",
      "1       44       29         1     -1         0    single     no\n",
      "2       33        2         1     -1         0   married     no\n",
      "3       47     1506         1     -1         0   married     no\n",
      "4       33        1         1     -1         0    single     no\n",
      "...    ...      ...       ...    ...       ...       ...    ...\n",
      "45206   51      825         3     -1         0   married    yes\n",
      "45207   71     1729         2     -1         0  divorced    yes\n",
      "45208   72     5715         5    184         3   married    yes\n",
      "45209   57      668         4     -1         0   married     no\n",
      "45210   37     2971         2    188        11   married     no\n",
      "\n",
      "[45211 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "features_adult = [\"age\", \"education-num\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]\n",
    "\n",
    "features_credit_card = [\"limit_bal\", \"education\", \"age\", \"pay_0\", *[f\"pay_{i}\" for i in range(2, 7)], *[f\"bill_amt{i}\" for i in range(1, 7)], *[f\"pay_amt{i}\" for i in range(1, 7)]]\n",
    "\n",
    "# \"duration\" not included as specified on https://archive.ics.uci.edu/dataset/222/bank+marketing\n",
    "features_bank_marketing = [\"age\", \"balance\", \"campaign\", \"pdays\", \"previous\"]\n",
    "\n",
    "adult_preprocessed = prepare_dataset(\n",
    "    adult,\n",
    "    features=features_adult,\n",
    "    sensitive_attribute=\"sex\",\n",
    "    convert_target=lambda income: income == \">50K\",\n",
    ")\n",
    "credit_preprocessed = prepare_dataset(\n",
    "    credit_card,\n",
    "    features_credit_card,\n",
    "    sensitive_attribute=\"sex\",\n",
    ")\n",
    "bank_preprocessed = prepare_dataset(\n",
    "    bank_marketing,\n",
    "    features_bank_marketing,\n",
    "    sensitive_attribute=\"marital\",\n",
    "    convert_target=lambda default: default == \"yes\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02599598  1.136512    0.14693247 -0.2171271  -0.03408696]\n",
      " [ 0.82830842  1.136512   -0.14480353 -0.2171271  -2.21303208]\n",
      " [-0.04694151 -0.41933527 -0.14480353 -0.2171271  -0.03408696]\n",
      " ...\n",
      " [-0.04694151  1.136512   -0.14480353 -0.2171271   0.77292975]\n",
      " [ 0.39068346  1.136512    0.58722034 -0.2171271  -0.03408696]\n",
      " [-0.26575399  1.136512   -0.14480353 -0.2171271   1.57994645]]\n",
      "[0 0 0 ... 0 0 0]\n",
      "['Male' 'Male' 'Male' ... 'Male' 'Male' 'Male']\n"
     ]
    }
   ],
   "source": [
    "for arr in adult_preprocessed:\n",
    "    print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42   # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def assess_fairness(X, y, sensitive_attribute, model, k=20):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    metrics = {\n",
    "        group: {\"TPR\": [], \"FPR\": [], \"FN_FP_ratio\": []}\n",
    "        for group in np.unique(sensitive_attribute)\n",
    "    }\n",
    "\n",
    "    total_accuracy = 0    # Not for statistical testing, just for visualization later\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        _sensitive_train, sensitive_test = (\n",
    "            sensitive_attribute[train_index],\n",
    "            sensitive_attribute[test_index],\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        for group in np.unique(sensitive_attribute):\n",
    "            group_mask = sensitive_test == group\n",
    "            tn, fp, fn, tp = confusion_matrix(\n",
    "                y_test[group_mask], y_pred[group_mask]\n",
    "            ).ravel()\n",
    "            f1 = f1_score(y_test[group_mask], y_pred[group_mask])\n",
    "\n",
    "            tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "            fn_fp_ratio = fn / fp if fp > 0 else 0\n",
    "\n",
    "            metrics[group][\"TPR\"].append(tpr)\n",
    "            metrics[group][\"FPR\"].append(fpr)\n",
    "            metrics[group][\"FN_FP_ratio\"].append(fn_fp_ratio)\n",
    "\n",
    "        total_accuracy += accuracy_score(y_test, y_pred)\n",
    "    metrics[\"accuracy\"] = total_accuracy / k\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS_TO_TEST = [\"TPR\", \"FPR\", \"FN_FP_ratio\"]\n",
    "\n",
    "def statistical_test(metrics, groups):\n",
    "    results = {}\n",
    "    if len(groups) == 2:\n",
    "        results = statistical_t_test(metrics, *groups)\n",
    "    else:\n",
    "        results = statistical_anova_test(metrics, *groups)\n",
    "    results[\"accuracy\"] = metrics[\"accuracy\"]\n",
    "    return results\n",
    "\n",
    "def statistical_anova_test(metrics, *groups):\n",
    "    # Perform one-way ANOVA for more than two groups\n",
    "    results = {}\n",
    "    for metric in METRICS_TO_TEST:\n",
    "        data = []\n",
    "        group_labels = []\n",
    "        for group in groups:\n",
    "            data.extend(metrics[group][metric])\n",
    "            group_labels.extend([group] * len(metrics[group][metric]))\n",
    "        \n",
    "        f_stat, p_value = stats.f_oneway(*[metrics[group][metric] for group in groups])\n",
    "        results[metric] = {\n",
    "            \"test\": \"ANOVA\",\n",
    "            \"statistic\": f_stat,\n",
    "            \"p_value\": p_value\n",
    "        }\n",
    "\n",
    "        # Perform post-hoc Tukey's HSD test\n",
    "        tukey_results = stats.tukey_hsd(*[metrics[group][metric] for group in groups])\n",
    "        results[metric][\"post_hoc\"] = tukey_results\n",
    "    return results\n",
    "\n",
    "def statistical_t_test(metrics, group1, group2):\n",
    "    results = {}\n",
    "    for metric in METRICS_TO_TEST:\n",
    "        t_stat, p_value = stats.ttest_ind(\n",
    "            metrics[group1][metric], metrics[group2][metric]\n",
    "        )\n",
    "        results[metric] = {\n",
    "            \"test\": \"t-test\",\n",
    "            \"statistic\": t_stat,\n",
    "            \"p_value\": p_value\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_ALL_PROCESSORS = -1\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=RANDOM_STATE, n_jobs=USE_ALL_PROCESSORS),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=USE_ALL_PROCESSORS),\n",
    "    \"Support Vector Machine\": SVC(random_state=RANDOM_STATE),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_jobs=USE_ALL_PROCESSORS),\n",
    "}\n",
    "description_to_acronym = {\n",
    "    \"Logistic Regression\": \"LR\",\n",
    "    \"Random Forest\": \"RF\",\n",
    "    \"Support Vector Machine\": \"SVM\",\n",
    "    \"K-Nearest Neighbors\": \"KNN\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATISTIC_SIGNIFICANCE_MAXIMUM = 0.05\n",
    "\n",
    "def run_dataset(X, y, sensitive_attribute, out_file = None):\n",
    "    model_results = {}\n",
    "    # Assess fairness for each model\n",
    "    for i, (model_name, model) in enumerate(models.items()):\n",
    "        print(f\"\\n\\n### {i + 1}. Assessing fairness for {model_name}\", file=out_file)\n",
    "        metrics = assess_fairness(X, y, sensitive_attribute, model)\n",
    "\n",
    "        # Print average metrics for each group\n",
    "        groups = np.unique(sensitive_attribute)\n",
    "        for group in groups:\n",
    "            print(f\"\\n\\nGroup: **{group}**\", file=out_file)\n",
    "            for metric, values in metrics[group].items():\n",
    "                print(f\"\\n- {metric}: {np.mean(values):.4f}\", file=out_file)\n",
    "\n",
    "        # Perform statistical test\n",
    "        results = statistical_test(metrics, groups)\n",
    "        print(\"\\n\\n#### Statistical Test Results:\", file=out_file)\n",
    "        for metric in METRICS_TO_TEST:\n",
    "            statistics = results[metric]\n",
    "            print(f\"\\n- {metric}:\", file=out_file)\n",
    "            print(f\"\\n\\t- Test: {statistics['test']}\", file=out_file)\n",
    "            print(f\"\\n\\t- Statistic: {statistics['statistic']:.4f}\", file=out_file)\n",
    "            print(f\"\\n\\t- p-value: {statistics['p_value']:.4f}\", file=out_file)\n",
    "\n",
    "            if statistics['test'] == \"ANOVA\" and statistics['p_value'] < STATISTIC_SIGNIFICANCE_MAXIMUM:\n",
    "                print(\"\\n\\t- Post-hoc Tukey HSD Results:\", file=out_file)\n",
    "                print(\"\\n```\", file=out_file)\n",
    "                print(statistics['post_hoc'], file=out_file)\n",
    "                print(\"\\n```\", file=out_file)\n",
    "\n",
    "        model_results[model_name] = results\n",
    "\n",
    "        print(f\"\\n\\n**Overall average accuracy**: {metrics[\"accuracy\"]:.3f}\", file=out_file)\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"output.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could have redirected sys.stdout directly to a file, but this approach is more flexible\n",
    "def run(out_file):\n",
    "    print(\"# Training and testing models for biases\", file=out_file)\n",
    "    dataset_results = {}\n",
    "    for name, dataset in zip(dataset_names, [adult_preprocessed, credit_preprocessed, bank_preprocessed]):\n",
    "        print(f\"## Dataset {name}\", file=out_file)\n",
    "        X, y, sensitive_attribute = dataset\n",
    "        results = run_dataset(X, y, sensitive_attribute, out_file=out_file)\n",
    "        dataset_results[name] = results\n",
    "    return dataset_results\n",
    "\n",
    "results = None\n",
    "with open(output_file, \"w\") as f:\n",
    "    results = run(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| **Metrics** | **KNN** | **LR** | **RF** | **SVM** |\n",
       "| --- | --- | --- | --- | --- |\n",
       "| Dataset **Adult**  \n",
       "| TPR| 0.0003 | < 0.0001 | 0.0244 | **-** |\n",
       "| FPR| < 0.0001 | < 0.0001 | < 0.0001 | < 0.0001 |\n",
       "| FN_FP_ratio| < 0.0001 | 0.0462 | < 0.0001 | **-** |\n",
       "| Accuracy| 0.817 | 0.842 | 0.843 | 0.853 |\n",
       "| Dataset **Credit**  \n",
       "| TPR| **-** | **-** | **-** | **-** |\n",
       "| FPR| 0.0002 | 0.0004 | < 0.0001 | 0.0030 |\n",
       "| FN_FP_ratio| **-** | **-** | **-** | **-** |\n",
       "| Accuracy| 0.794 | 0.810 | 0.815 | 0.820 |\n",
       "| Dataset **Bank**  \n",
       "| TPR| **-** | **-** | 0.0035 | 0.0009 |\n",
       "| FPR| 0.0002 | **-** | < 0.0001 | 0.0102 |\n",
       "| FN_FP_ratio| 0.0014 | 0.0004 | 0.0002 | < 0.0001 |\n",
       "| Accuracy| 0.873 | 0.882 | 0.856 | 0.883 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_p_value(p: float) -> str:\n",
    "    if p >= STATISTIC_SIGNIFICANCE_MAXIMUM:\n",
    "        return \"**-**\"\n",
    "    limit = 0.0001\n",
    "    return f\"< {limit}\" if p < limit else f\"{p:.4f}\"\n",
    "\n",
    "\n",
    "def fill_dataset_table_rows(\n",
    "    dict: Mapping[str, Mapping[str, float]], format_func: Callable[[float], str]\n",
    "):\n",
    "    row_str = \"\"\n",
    "    for stat, values in dict.items():\n",
    "        values.sort()  # Sort by the model acronym to ensure consistent ordering\n",
    "        row_str += f\"| {stat}\"\n",
    "        row_str += \"| \" + \" | \".join(\n",
    "            [f\"{format_func(value)}\" for _model, value in values]\n",
    "        )\n",
    "        row_str += \" |\\n\"\n",
    "    return row_str\n",
    "\n",
    "\n",
    "table_str = (\n",
    "    \"| **Metrics** | \"\n",
    "    + \" | \".join(\n",
    "        map(\n",
    "            lambda name: f\"**{name}**\",\n",
    "            sorted(  # Sort by the model acronym to ensure consistent ordering\n",
    "                map(\n",
    "                    lambda model_desc: description_to_acronym[model_desc], models.keys()\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    + \" |\\n\"\n",
    ")\n",
    "table_str += \"| --- | \" + \" | \".join([\"---\" for _ in models.keys()]) + \" |\\n\"\n",
    "for dataset, dataset_results in results.items():\n",
    "    table_str += f\"| Dataset **{dataset}**  \\n\"\n",
    "\n",
    "    statistic_values = {}\n",
    "    score_values = {}\n",
    "    for model, statistics in dataset_results.items():\n",
    "        model = description_to_acronym[model]  # e.g.: Use \"RF\" instead of Random Forest\n",
    "        for stat in METRICS_TO_TEST:\n",
    "            values = statistics[stat]\n",
    "            p_value = values[\"p_value\"]\n",
    "            statistic_values[stat] = statistic_values.get(stat, [])\n",
    "            statistic_values[stat].append((model, p_value))\n",
    "\n",
    "        score_values[\"Accuracy\"] = score_values.get(\"Accuracy\", [])\n",
    "        score_values[\"Accuracy\"].append((model, statistics[\"accuracy\"]))\n",
    "\n",
    "    table_str += fill_dataset_table_rows(statistic_values, format_p_value)\n",
    "    table_str += fill_dataset_table_rows(score_values, lambda x: f\"{x:.3f}\")\n",
    "\n",
    "output_file_table = \"output_table.md\"\n",
    "with open(output_file_table, \"w\") as f:\n",
    "    f.write(table_str)\n",
    "\n",
    "Markdown(table_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is the last one, and has an extensive output.\n",
    "\n",
    "For each dataset, and for each model, it shows information about the different metrics $FPR$, $TPR$ and $\\frac{FN}{FP}$. For each group, it will show the mean value of these metrics, as well as the statistical test result of comparing the values of the metric across groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Training and testing models for biases\n",
       "## Dataset Adult\n",
       "\n",
       "\n",
       "### 1. Assessing fairness for Logistic Regression\n",
       "\n",
       "\n",
       "Group: **Female**\n",
       "\n",
       "- TPR: 0.0863\n",
       "\n",
       "- FPR: 0.0111\n",
       "\n",
       "- FN_FP_ratio: 7.5206\n",
       "\n",
       "\n",
       "Group: **Male**\n",
       "\n",
       "- TPR: 0.1262\n",
       "\n",
       "- FPR: 0.0248\n",
       "\n",
       "- FN_FP_ratio: 9.2278\n",
       "\n",
       "\n",
       "#### Statistical Test Results:\n",
       "\n",
       "- TPR:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: -4.8139\n",
       "\n",
       "\t- p-value: 0.0000\n",
       "\n",
       "- FPR:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: -11.0649\n",
       "\n",
       "\t- p-value: 0.0000\n",
       "\n",
       "- FN_FP_ratio:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: -2.0613\n",
       "\n",
       "\t- p-value: 0.0462\n",
       "\n",
       "\n",
       "**Overall average accuracy**: 0.842\n",
       "\n",
       "\n",
       "### 2. Assessing fairness for Random Forest\n",
       "\n",
       "\n",
       "Group: **Female**\n",
       "\n",
       "- TPR: 0.2556\n",
       "\n",
       "- FPR: 0.0335\n",
       "\n",
       "- FN_FP_ratio: 1.7676\n",
       "\n",
       "\n",
       "Group: **Male**\n",
       "\n",
       "- TPR: 0.2892\n",
       "\n",
       "- FPR: 0.0596\n",
       "\n",
       "- FN_FP_ratio: 3.0884\n",
       "\n",
       "\n",
       "#### Statistical Test Results:\n",
       "\n",
       "- TPR:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: -2.3445\n",
       "\n",
       "\t- p-value: 0.0244\n",
       "\n",
       "- FPR:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: -15.3159\n",
       "\n",
       "\t- p-value: 0.0000\n",
       "\n",
       "- FN_FP_ratio:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: -12.4910\n",
       "\n",
       "\t- p-value: 0.0000\n",
       "\n",
       "\n",
       "**Overall average accuracy**: 0.843\n",
       "\n",
       "\n",
       "### 3. Assessing fairness for Support Vector Machine\n",
       "\n",
       "\n",
       "Group: **Female**\n",
       "\n",
       "- TPR: 0.1843\n",
       "\n",
       "- FPR: 0.0092\n",
       "\n",
       "- FN_FP_ratio: 9.2422\n",
       "\n",
       "\n",
       "Group: **Male**\n",
       "\n",
       "- TPR: 0.1793\n",
       "\n",
       "- FPR: 0.0244\n",
       "\n",
       "- FN_FP_ratio: 8.8223\n",
       "\n",
       "\n",
       "#### Statistical Test Results:\n",
       "\n",
       "- TPR:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: 0.3714\n",
       "\n",
       "\t- p-value: 0.7124\n",
       "\n",
       "- FPR:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: -11.9265\n",
       "\n",
       "\t- p-value: 0.0000\n",
       "\n",
       "- FN_FP_ratio:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: 0.2874\n",
       "\n",
       "\t- p-value: 0.7754\n",
       "\n",
       "\n",
       "**Overall average accuracy**: 0.853\n",
       "\n",
       "\n",
       "### 4. Assessing fairness for K-Nearest Neighbors\n",
       "\n",
       "\n",
       "Group: **Female**\n",
       "\n",
       "- TPR: 0.3198\n",
       "\n",
       "- FPR: 0.0723\n",
       "\n",
       "- FN_FP_ratio: 0.7517\n",
       "\n",
       "\n",
       "Group: **Male**\n",
       "\n",
       "- TPR: 0.3661\n",
       "\n",
       "- FPR: 0.1090\n",
       "\n",
       "- FN_FP_ratio: 1.5051\n",
       "\n",
       "\n",
       "#### Statistical Test Results:\n",
       "\n",
       "- TPR:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: -3.9426\n",
       "\n",
       "\t- p-value: 0.0003\n",
       "\n",
       "- FPR:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: -11.8540\n",
       "\n",
       "\t- p-value: 0.0000\n",
       "\n",
       "- FN_FP_ratio:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: -14.1194\n",
       "\n",
       "\t- p-value: 0.0000\n",
       "\n",
       "\n",
       "**Overall average accuracy**: 0.817\n",
       "## Dataset Credit\n",
       "\n",
       "\n",
       "### 1. Assessing fairness for Logistic Regression\n",
       "\n",
       "\n",
       "Group: **1**\n",
       "\n",
       "- TPR: 0.2411\n",
       "\n",
       "- FPR: 0.0327\n",
       "\n",
       "- FN_FP_ratio: 8.1295\n",
       "\n",
       "\n",
       "Group: **2**\n",
       "\n",
       "- TPR: 0.2309\n",
       "\n",
       "- FPR: 0.0228\n",
       "\n",
       "- FN_FP_ratio: 9.8724\n",
       "\n",
       "\n",
       "#### Statistical Test Results:\n",
       "\n",
       "- TPR:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: 1.0203\n",
       "\n",
       "\t- p-value: 0.3141\n",
       "\n",
       "- FPR:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: 3.8938\n",
       "\n",
       "\t- p-value: 0.0004\n",
       "\n",
       "- FN_FP_ratio:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: -1.6678\n",
       "\n",
       "\t- p-value: 0.1036\n",
       "\n",
       "\n",
       "**Overall average accuracy**: 0.810\n",
       "\n",
       "\n",
       "### 2. Assessing fairness for Random Forest\n",
       "\n",
       "\n",
       "Group: **1**\n",
       "\n",
       "- TPR: 0.3770\n",
       "\n",
       "- FPR: 0.0675\n",
       "\n",
       "- FN_FP_ratio: 3.0086\n",
       "\n",
       "\n",
       "Group: **2**\n",
       "\n",
       "- TPR: 0.3673\n",
       "\n",
       "- FPR: 0.0532\n",
       "\n",
       "- FN_FP_ratio: 3.1822\n",
       "\n",
       "\n",
       "#### Statistical Test Results:\n",
       "\n",
       "- TPR:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: 0.8113\n",
       "\n",
       "\t- p-value: 0.4223\n",
       "\n",
       "- FPR:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: 4.7039\n",
       "\n",
       "\t- p-value: 0.0000\n",
       "\n",
       "- FN_FP_ratio:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: -1.0256\n",
       "\n",
       "\t- p-value: 0.3116\n",
       "\n",
       "\n",
       "**Overall average accuracy**: 0.815\n",
       "\n",
       "\n",
       "### 3. Assessing fairness for Support Vector Machine\n",
       "\n",
       "\n",
       "Group: **1**\n",
       "\n",
       "- TPR: 0.3490\n",
       "\n",
       "- FPR: 0.0502\n",
       "\n",
       "- FN_FP_ratio: 4.3095\n",
       "\n",
       "\n",
       "Group: **2**\n",
       "\n",
       "- TPR: 0.3334\n",
       "\n",
       "- FPR: 0.0405\n",
       "\n",
       "- FN_FP_ratio: 4.5481\n",
       "\n",
       "\n",
       "#### Statistical Test Results:\n",
       "\n",
       "- TPR:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: 1.3244\n",
       "\n",
       "\t- p-value: 0.1933\n",
       "\n",
       "- FPR:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: 3.1773\n",
       "\n",
       "\t- p-value: 0.0030\n",
       "\n",
       "- FN_FP_ratio:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: -0.7151\n",
       "\n",
       "\t- p-value: 0.4789\n",
       "\n",
       "\n",
       "**Overall average accuracy**: 0.820\n",
       "\n",
       "\n",
       "### 4. Assessing fairness for K-Nearest Neighbors\n",
       "\n",
       "\n",
       "Group: **1**\n",
       "\n",
       "- TPR: 0.3644\n",
       "\n",
       "- FPR: 0.0939\n",
       "\n",
       "- FN_FP_ratio: 2.2357\n",
       "\n",
       "\n",
       "Group: **2**\n",
       "\n",
       "- TPR: 0.3586\n",
       "\n",
       "- FPR: 0.0772\n",
       "\n",
       "- FN_FP_ratio: 2.2158\n",
       "\n",
       "\n",
       "#### Statistical Test Results:\n",
       "\n",
       "- TPR:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: 0.4569\n",
       "\n",
       "\t- p-value: 0.6504\n",
       "\n",
       "- FPR:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: 4.1443\n",
       "\n",
       "\t- p-value: 0.0002\n",
       "\n",
       "- FN_FP_ratio:\n",
       "\n",
       "\t- Test: t-test\n",
       "\n",
       "\t- Statistic: 0.1321\n",
       "\n",
       "\t- p-value: 0.8956\n",
       "\n",
       "\n",
       "**Overall average accuracy**: 0.794\n",
       "## Dataset Bank\n",
       "\n",
       "\n",
       "### 1. Assessing fairness for Logistic Regression\n",
       "\n",
       "\n",
       "Group: **divorced**\n",
       "\n",
       "- TPR: 0.0055\n",
       "\n",
       "- FPR: 0.0011\n",
       "\n",
       "- FN_FP_ratio: 7.3500\n",
       "\n",
       "\n",
       "Group: **married**\n",
       "\n",
       "- TPR: 0.0018\n",
       "\n",
       "- FPR: 0.0009\n",
       "\n",
       "- FN_FP_ratio: 64.1250\n",
       "\n",
       "\n",
       "Group: **single**\n",
       "\n",
       "- TPR: 0.0015\n",
       "\n",
       "- FPR: 0.0011\n",
       "\n",
       "- FN_FP_ratio: 48.3250\n",
       "\n",
       "\n",
       "#### Statistical Test Results:\n",
       "\n",
       "- TPR:\n",
       "\n",
       "\t- Test: ANOVA\n",
       "\n",
       "\t- Statistic: 1.3902\n",
       "\n",
       "\t- p-value: 0.2573\n",
       "\n",
       "- FPR:\n",
       "\n",
       "\t- Test: ANOVA\n",
       "\n",
       "\t- Statistic: 0.1435\n",
       "\n",
       "\t- p-value: 0.8666\n",
       "\n",
       "- FN_FP_ratio:\n",
       "\n",
       "\t- Test: ANOVA\n",
       "\n",
       "\t- Statistic: 8.9794\n",
       "\n",
       "\t- p-value: 0.0004\n",
       "\n",
       "\t- Post-hoc Tukey HSD Results:\n",
       "\n",
       "```\n",
       "Tukey's HSD Pairwise Group Comparisons (95.0% Confidence Interval)\n",
       "Comparison  Statistic  p-value  Lower CI  Upper CI\n",
       " (0 - 1)    -56.775     0.000   -90.054   -23.496\n",
       " (0 - 2)    -40.975     0.012   -74.254    -7.696\n",
       " (1 - 0)     56.775     0.000    23.496    90.054\n",
       " (1 - 2)     15.800     0.492   -17.479    49.079\n",
       " (2 - 0)     40.975     0.012     7.696    74.254\n",
       " (2 - 1)    -15.800     0.492   -49.079    17.479\n",
       "\n",
       "\n",
       "```\n",
       "\n",
       "\n",
       "**Overall average accuracy**: 0.882\n",
       "\n",
       "\n",
       "### 2. Assessing fairness for Random Forest\n",
       "\n",
       "\n",
       "Group: **divorced**\n",
       "\n",
       "- TPR: 0.1273\n",
       "\n",
       "- FPR: 0.0394\n",
       "\n",
       "- FN_FP_ratio: 3.2912\n",
       "\n",
       "\n",
       "Group: **married**\n",
       "\n",
       "- TPR: 0.1617\n",
       "\n",
       "- FPR: 0.0476\n",
       "\n",
       "- FN_FP_ratio: 2.0068\n",
       "\n",
       "\n",
       "Group: **single**\n",
       "\n",
       "- TPR: 0.1681\n",
       "\n",
       "- FPR: 0.0653\n",
       "\n",
       "- FN_FP_ratio: 2.3311\n",
       "\n",
       "\n",
       "#### Statistical Test Results:\n",
       "\n",
       "- TPR:\n",
       "\n",
       "\t- Test: ANOVA\n",
       "\n",
       "\t- Statistic: 6.2536\n",
       "\n",
       "\t- p-value: 0.0035\n",
       "\n",
       "\t- Post-hoc Tukey HSD Results:\n",
       "\n",
       "```\n",
       "Tukey's HSD Pairwise Group Comparisons (95.0% Confidence Interval)\n",
       "Comparison  Statistic  p-value  Lower CI  Upper CI\n",
       " (0 - 1)     -0.034     0.020    -0.064    -0.005\n",
       " (0 - 2)     -0.041     0.005    -0.071    -0.011\n",
       " (1 - 0)      0.034     0.020     0.005     0.064\n",
       " (1 - 2)     -0.006     0.864    -0.036     0.023\n",
       " (2 - 0)      0.041     0.005     0.011     0.071\n",
       " (2 - 1)      0.006     0.864    -0.023     0.036\n",
       "\n",
       "\n",
       "```\n",
       "\n",
       "- FPR:\n",
       "\n",
       "\t- Test: ANOVA\n",
       "\n",
       "\t- Statistic: 38.1462\n",
       "\n",
       "\t- p-value: 0.0000\n",
       "\n",
       "\t- Post-hoc Tukey HSD Results:\n",
       "\n",
       "```\n",
       "Tukey's HSD Pairwise Group Comparisons (95.0% Confidence Interval)\n",
       "Comparison  Statistic  p-value  Lower CI  Upper CI\n",
       " (0 - 1)     -0.008     0.025    -0.015    -0.001\n",
       " (0 - 2)     -0.026     0.000    -0.033    -0.019\n",
       " (1 - 0)      0.008     0.025     0.001     0.015\n",
       " (1 - 2)     -0.018     0.000    -0.025    -0.010\n",
       " (2 - 0)      0.026     0.000     0.019     0.033\n",
       " (2 - 1)      0.018     0.000     0.010     0.025\n",
       "\n",
       "\n",
       "```\n",
       "\n",
       "- FN_FP_ratio:\n",
       "\n",
       "\t- Test: ANOVA\n",
       "\n",
       "\t- Statistic: 10.2948\n",
       "\n",
       "\t- p-value: 0.0002\n",
       "\n",
       "\t- Post-hoc Tukey HSD Results:\n",
       "\n",
       "```\n",
       "Tukey's HSD Pairwise Group Comparisons (95.0% Confidence Interval)\n",
       "Comparison  Statistic  p-value  Lower CI  Upper CI\n",
       " (0 - 1)      1.284     0.000     0.576     1.993\n",
       " (0 - 2)      0.960     0.005     0.252     1.669\n",
       " (1 - 0)     -1.284     0.000    -1.993    -0.576\n",
       " (1 - 2)     -0.324     0.517    -1.033     0.384\n",
       " (2 - 0)     -0.960     0.005    -1.669    -0.252\n",
       " (2 - 1)      0.324     0.517    -0.384     1.033\n",
       "\n",
       "\n",
       "```\n",
       "\n",
       "\n",
       "**Overall average accuracy**: 0.856\n",
       "\n",
       "\n",
       "### 3. Assessing fairness for Support Vector Machine\n",
       "\n",
       "\n",
       "Group: **divorced**\n",
       "\n",
       "- TPR: 0.0082\n",
       "\n",
       "- FPR: 0.0029\n",
       "\n",
       "- FN_FP_ratio: 8.6083\n",
       "\n",
       "\n",
       "Group: **married**\n",
       "\n",
       "- TPR: 0.0154\n",
       "\n",
       "- FPR: 0.0014\n",
       "\n",
       "- FN_FP_ratio: 71.0275\n",
       "\n",
       "\n",
       "Group: **single**\n",
       "\n",
       "- TPR: 0.0010\n",
       "\n",
       "- FPR: 0.0003\n",
       "\n",
       "- FN_FP_ratio: 6.4250\n",
       "\n",
       "\n",
       "#### Statistical Test Results:\n",
       "\n",
       "- TPR:\n",
       "\n",
       "\t- Test: ANOVA\n",
       "\n",
       "\t- Statistic: 8.0164\n",
       "\n",
       "\t- p-value: 0.0009\n",
       "\n",
       "\t- Post-hoc Tukey HSD Results:\n",
       "\n",
       "```\n",
       "Tukey's HSD Pairwise Group Comparisons (95.0% Confidence Interval)\n",
       "Comparison  Statistic  p-value  Lower CI  Upper CI\n",
       " (0 - 1)     -0.007     0.119    -0.016     0.001\n",
       " (0 - 2)      0.007     0.123    -0.001     0.016\n",
       " (1 - 0)      0.007     0.119    -0.001     0.016\n",
       " (1 - 2)      0.014     0.001     0.006     0.023\n",
       " (2 - 0)     -0.007     0.123    -0.016     0.001\n",
       " (2 - 1)     -0.014     0.001    -0.023    -0.006\n",
       "\n",
       "\n",
       "```\n",
       "\n",
       "- FPR:\n",
       "\n",
       "\t- Test: ANOVA\n",
       "\n",
       "\t- Statistic: 4.9766\n",
       "\n",
       "\t- p-value: 0.0102\n",
       "\n",
       "\t- Post-hoc Tukey HSD Results:\n",
       "\n",
       "```\n",
       "Tukey's HSD Pairwise Group Comparisons (95.0% Confidence Interval)\n",
       "Comparison  Statistic  p-value  Lower CI  Upper CI\n",
       " (0 - 1)      0.001     0.199    -0.001     0.003\n",
       " (0 - 2)      0.003     0.007     0.001     0.005\n",
       " (1 - 0)     -0.001     0.199    -0.003     0.001\n",
       " (1 - 2)      0.001     0.343    -0.001     0.003\n",
       " (2 - 0)     -0.003     0.007    -0.005    -0.001\n",
       " (2 - 1)     -0.001     0.343    -0.003     0.001\n",
       "\n",
       "\n",
       "```\n",
       "\n",
       "- FN_FP_ratio:\n",
       "\n",
       "\t- Test: ANOVA\n",
       "\n",
       "\t- Statistic: 20.8280\n",
       "\n",
       "\t- p-value: 0.0000\n",
       "\n",
       "\t- Post-hoc Tukey HSD Results:\n",
       "\n",
       "```\n",
       "Tukey's HSD Pairwise Group Comparisons (95.0% Confidence Interval)\n",
       "Comparison  Statistic  p-value  Lower CI  Upper CI\n",
       " (0 - 1)    -62.419     0.000   -89.774   -35.064\n",
       " (0 - 2)      2.183     0.980   -25.172    29.539\n",
       " (1 - 0)     62.419     0.000    35.064    89.774\n",
       " (1 - 2)     64.603     0.000    37.247    91.958\n",
       " (2 - 0)     -2.183     0.980   -29.539    25.172\n",
       " (2 - 1)    -64.603     0.000   -91.958   -37.247\n",
       "\n",
       "\n",
       "```\n",
       "\n",
       "\n",
       "**Overall average accuracy**: 0.883\n",
       "\n",
       "\n",
       "### 4. Assessing fairness for K-Nearest Neighbors\n",
       "\n",
       "\n",
       "Group: **divorced**\n",
       "\n",
       "- TPR: 0.1048\n",
       "\n",
       "- FPR: 0.0224\n",
       "\n",
       "- FN_FP_ratio: 6.7439\n",
       "\n",
       "\n",
       "Group: **married**\n",
       "\n",
       "- TPR: 0.1294\n",
       "\n",
       "- FPR: 0.0250\n",
       "\n",
       "- FN_FP_ratio: 4.1000\n",
       "\n",
       "\n",
       "Group: **single**\n",
       "\n",
       "- TPR: 0.1066\n",
       "\n",
       "- FPR: 0.0335\n",
       "\n",
       "- FN_FP_ratio: 4.9838\n",
       "\n",
       "\n",
       "#### Statistical Test Results:\n",
       "\n",
       "- TPR:\n",
       "\n",
       "\t- Test: ANOVA\n",
       "\n",
       "\t- Statistic: 2.9535\n",
       "\n",
       "\t- p-value: 0.0602\n",
       "\n",
       "- FPR:\n",
       "\n",
       "\t- Test: ANOVA\n",
       "\n",
       "\t- Statistic: 9.8601\n",
       "\n",
       "\t- p-value: 0.0002\n",
       "\n",
       "\t- Post-hoc Tukey HSD Results:\n",
       "\n",
       "```\n",
       "Tukey's HSD Pairwise Group Comparisons (95.0% Confidence Interval)\n",
       "Comparison  Statistic  p-value  Lower CI  Upper CI\n",
       " (0 - 1)     -0.003     0.583    -0.009     0.004\n",
       " (0 - 2)     -0.011     0.000    -0.017    -0.005\n",
       " (1 - 0)      0.003     0.583    -0.004     0.009\n",
       " (1 - 2)     -0.009     0.005    -0.015    -0.002\n",
       " (2 - 0)      0.011     0.000     0.005     0.017\n",
       " (2 - 1)      0.009     0.005     0.002     0.015\n",
       "\n",
       "\n",
       "```\n",
       "\n",
       "- FN_FP_ratio:\n",
       "\n",
       "\t- Test: ANOVA\n",
       "\n",
       "\t- Statistic: 7.3630\n",
       "\n",
       "\t- p-value: 0.0014\n",
       "\n",
       "\t- Post-hoc Tukey HSD Results:\n",
       "\n",
       "```\n",
       "Tukey's HSD Pairwise Group Comparisons (95.0% Confidence Interval)\n",
       "Comparison  Statistic  p-value  Lower CI  Upper CI\n",
       " (0 - 1)      2.644     0.001     0.956     4.332\n",
       " (0 - 2)      1.760     0.039     0.072     3.448\n",
       " (1 - 0)     -2.644     0.001    -4.332    -0.956\n",
       " (1 - 2)     -0.884     0.423    -2.572     0.804\n",
       " (2 - 0)     -1.760     0.039    -3.448    -0.072\n",
       " (2 - 1)      0.884     0.423    -0.804     2.572\n",
       "\n",
       "\n",
       "```\n",
       "\n",
       "\n",
       "**Overall average accuracy**: 0.873\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(output_file) as f:\n",
    "    display(Markdown(f.read()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
